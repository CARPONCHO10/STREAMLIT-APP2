import time
import numpy as np
import cv2
import streamlit as st
import pandas as pd
import sqlite3
import os
import sys
from datetime import datetime
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration, VideoTransformerBase

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Clasificador en vivo", 
    page_icon="üé•", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üé• Clasificaci√≥n en vivo con Keras + Streamlit")
st.caption("C√°mara dentro de la p√°gina y resultados en la misma interfaz. Incluye selector de c√°mara/calidad y registro a CSV.")

# Constantes
MODEL_PATH = "keras_model.h5"
LABELS_PATH = "labels.txt"
DB_PATH = "predicciones.db"

# =============================================================================
# 1. VERIFICACI√ìN INICIAL DE ARCHIVOS Y DEPENDENCIAS
# =============================================================================

def verificar_archivos():
    """Verifica que todos los archivos necesarios existan"""
    st.sidebar.header("üìÅ Verificaci√≥n de archivos")
    
    archivos_requeridos = {
        "Modelo Keras": MODEL_PATH,
        "Etiquetas": LABELS_PATH,
        "Requirements": "requirements.txt"
    }
    
    # Listar todos los archivos en el directorio
    st.sidebar.write("**Todos los archivos en el directorio:**")
    try:
        files = os.listdir(".")
        for file in sorted(files):
            icon = "üìÑ" if os.path.isfile(file) else "üìÅ"
            st.sidebar.write(f"{icon} {file}")
    except Exception as e:
        st.sidebar.error(f"Error al listar archivos: {e}")
    
    # Verificar archivos requeridos
    todos_existen = True
    for nombre, archivo in archivos_requeridos.items():
        if os.path.exists(archivo):
            st.sidebar.success(f"‚úÖ {nombre}: {archivo}")
        else:
            st.sidebar.error(f"‚ùå {nombre}: {archivo} - NO ENCONTRADO")
            todos_existen = False
    
    return todos_existen

# Ejecutar verificaci√≥n
archivos_ok = verificar_archivos()

if not archivos_ok:
    st.error("""
    **‚ùå Faltan archivos esenciales**
    
    **Soluci√≥n:**
    1. Aseg√∫rate de que todos los archivos est√©n en tu repositorio de GitHub
    2. Verifica los nombres exactos (may√∫sculas/min√∫sculas)
    3. Los archivos deben estar en la ra√≠z del proyecto
    """)
    st.stop()

# =============================================================================
# 2. CONFIGURACI√ìN DE BASE DE DATOS
# =============================================================================

def init_db():
    """Inicializa la base de datos SQLite"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("""
            CREATE TABLE IF NOT EXISTS predicciones (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                label TEXT,
                confidence REAL
            )
        """)
        conn.commit()
        conn.close()
        st.sidebar.success("‚úÖ Base de datos inicializada")
    except Exception as e:
        st.sidebar.error(f"‚ùå Error en BD: {e}")

def save_prediction_to_db(timestamp, label, confidence):
    """Guarda una predicci√≥n en la base de datos"""
    try:
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        c.execute("INSERT INTO predicciones (timestamp, label, confidence) VALUES (?, ?, ?)",
                  (timestamp, label, confidence))
        conn.commit()
        conn.close()
    except Exception as e:
        st.sidebar.error(f"Error guardando en BD: {e}")

# Inicializar BD
init_db()

# =============================================================================
# 3. CARGA SEGURA DEL MODELO Y ETIQUETAS
# =============================================================================

@st.cache_resource
def load_model_cached(model_path: str):
    """
    Carga el modelo Keras con manejo de errores y compatibilidad
    """
    try:
        # Primero intentar importar tensorflow
        try:
            from tensorflow.keras.models import load_model
        except ImportError as e:
            st.error(f"‚ùå TensorFlow no est√° instalado: {e}")
            st.stop()
        
        # Intentar carga con custom_objects si existe
        try:
            from custom_objects import load_model_with_fixes
            model = load_model_with_fixes(model_path)
            st.sidebar.success("‚úÖ Modelo cargado con custom_objects")
            return model
        except ImportError:
            # Si no existe custom_objects, intentar carga normal
            st.sidebar.info("‚ÑπÔ∏è Cargando modelo sin custom_objects...")
            model = load_model(model_path, compile=False)
            st.sidebar.success("‚úÖ Modelo cargado normalmente")
            return model
            
    except Exception as e:
        st.error(f"""
        **‚ùå Error cr√≠tico al cargar el modelo**
        
        **Detalle del error:** {str(e)}
        
        **Posibles soluciones:**
        1. Verifica que el modelo sea compatible con TensorFlow 2.20
        2. El archivo .h5 podr√≠a estar corrupto
        3. Intenta reconvertir el modelo
        """)
        # Intentar una √∫ltima vez sin cache
        try:
            from tensorflow.keras.models import load_model
            model = load_model(model_path, compile=False)
            st.sidebar.success("‚úÖ Modelo cargado en segundo intento")
            return model
        except:
            st.stop()

@st.cache_data
def load_labels(labels_path: str):
    """Carga las etiquetas desde el archivo de texto"""
    try:
        with open(labels_path, "r", encoding="utf-8") as f:
            labels = [line.strip() for line in f.readlines()]
        st.sidebar.success(f"‚úÖ {len(labels)} etiquetas cargadas")
        return labels
    except Exception as e:
        st.error(f"Error cargando etiquetas: {e}")
        # Crear etiquetas por defecto basadas en el n√∫mero de clases
        return [f"Clase {i}" for i in range(10)]

# Cargar modelo y etiquetas
with st.spinner("üîÑ Cargando modelo y etiquetas (esto puede tomar unos segundos)..."):
    try:
        model = load_model_cached(MODEL_PATH)
        labels = load_labels(LABELS_PATH)
        st.success(f"‚úÖ Sistema listo - Modelo: {len(labels)} clases")
    except Exception as e:
        st.error(f"Error durante la carga: {e}")
        st.stop()

# =============================================================================
# 4. CONFIGURACI√ìN DE LA INTERFAZ
# =============================================================================

# Sidebar - Configuraci√≥n de c√°mara
st.sidebar.header("üé¶ Ajustes de c√°mara")

facing = st.sidebar.selectbox(
    "Tipo de c√°mara", 
    options=["auto (por defecto)", "user (frontal)", "environment (trasera)"],
    index=0,
    help="Selecciona la c√°mara a usar. En m√≥viles: 'user'=frontal, 'environment'=trasera"
)

quality = st.sidebar.selectbox(
    "Calidad de video",
    options=["640x480", "1280x720", "1920x1080"],
    index=1,
    help="Resoluci√≥n del video. Mayor resoluci√≥n = m√°s precisi√≥n pero m√°s uso de recursos"
)

# Procesar configuraci√≥n de video
w, h = map(int, quality.split("x"))
video_constraints = {"width": w, "height": h}
if facing != "auto (por defecto)":
    video_constraints["facingMode"] = facing.split(" ")[0]

media_constraints = {"video": video_constraints, "audio": False}

# Sidebar - Registro de datos
st.sidebar.header("üìä Registro de predicciones")

enable_log = st.sidebar.checkbox(
    "Habilitar registro (CSV + SQLite)", 
    value=True,
    help="Guarda todas las predicciones para an√°lisis posterior"
)

log_every_n_seconds = st.sidebar.slider(
    "Intervalo de registro (segundos)", 
    0.2, 5.0, 1.0, 0.2,
    help="Cada cu√°ntos segundos se guarda una predicci√≥n. Evita guardar demasiados datos similares"
)

# =============================================================================
# 5. INICIALIZACI√ìN DE SESI√ìN
# =============================================================================

if "pred_log" not in st.session_state:
    st.session_state.pred_log = pd.DataFrame(columns=["timestamp", "label", "confidence"])

if "last_log_ts" not in st.session_state:
    st.session_state.last_log_ts = 0.0

if "total_predictions" not in st.session_state:
    st.session_state.total_predictions = 0

# =============================================================================
# 6. CONFIGURACI√ìN WEBRTC
# =============================================================================

RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

class VideoTransformer(VideoTransformerBase):
    def __init__(self) -> None:
        self.latest = {"class": None, "confidence": 0.0}
        self.model = model
        self.labels = labels
        self.prediction_count = 0

    def transform(self, frame):
        try:
            # Convertir frame a array numpy
            img = frame.to_ndarray(format="bgr24")
            
            # Preprocesamiento para el modelo (224x224 como es t√≠pico en Keras)
            resized = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)
            x = resized.astype(np.float32).reshape(1, 224, 224, 3)
            x = (x / 127.5) - 1.0  # Normalizar a [-1, 1]

            # Realizar predicci√≥n
            pred = self.model.predict(x, verbose=0)
            idx = int(np.argmax(pred))
            label = self.labels[idx] if idx < len(self.labels) else f"Clase {idx}"
            conf = float(pred[0][idx])

            # Actualizar informaci√≥n m√°s reciente
            self.latest = {"class": label, "confidence": conf}
            self.prediction_count += 1
            st.session_state.total_predictions = self.prediction_count

            # Dibujar overlay en el video
            overlay = img.copy()
            text = f"{label} | {conf*100:.1f}%"
            
            # Fondo semitransparente para el texto
            cv2.rectangle(overlay, (5, 5), (5 + 12*len(text), 50), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, img, 0.3, 0, img)
            
            # Texto
            cv2.putText(img, text, (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 
                       1.0, (0, 255, 0), 2, cv2.LINE_AA)
            
            return img
            
        except Exception as e:
            # En caso de error, devolver frame original
            st.sidebar.error(f"Error en transform: {e}")
            return frame.to_ndarray(format="bgr24")

# =============================================================================
# 7. INTERFAZ PRINCIPAL
# =============================================================================

# Layout de dos columnas
left_col, right_col = st.columns([2, 1], gap="large")

with left_col:
    st.subheader("üìπ C√°mara en vivo")
    
    # Informaci√≥n de estado
    if st.session_state.total_predictions > 0:
        st.info(f"**Estad√≠sticas:** {st.session_state.total_predictions} predicciones realizadas")
    
    # Componente WebRTC
    webrtc_ctx = webrtc_streamer(
        key="keras-live-classification",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints=media_constraints,
        video_transformer_factory=VideoTransformer,
        async_processing=True,
    )
    
    # Informaci√≥n de ayuda
    with st.expander("üí° Consejos de uso"):
        st.write("""
        - **Navegador recomendado:** Chrome o Edge para mejor compatibilidad
        - **Permisos:** Aseg√∫rate de permitir el acceso a la c√°mara
        - **C√°mara frontal/trasera:** En m√≥viles, usa 'user' para frontal y 'environment' para trasera
        - **Rendimiento:** Si hay lag, reduce la calidad del video
        - **Iluminaci√≥n:** Mejor resultados con buena iluminaci√≥n
        """)

with right_col:
    st.subheader("üìä Resultados en tiempo real")
    
    # Placeholders para resultados din√°micos
    result_placeholder = st.empty()
    progress_placeholder = st.empty()
    stats_placeholder = st.empty()
    
    # Inicializar placeholders
    result_placeholder.info("‚è≥ Esperando activaci√≥n de la c√°mara...")
    progress_placeholder.progress(0)
    
    # Bot√≥n para limpiar registro
    if enable_log and not st.session_state.pred_log.empty:
        if st.button("üßπ Limpiar registro completo", use_container_width=True):
            st.session_state.pred_log = st.session_state.pred_log.iloc[0:0]
            st.session_state.last_log_ts = 0.0
            st.session_state.total_predictions = 0
            st.rerun()
    
    # Descargar CSV
    if not st.session_state.pred_log.empty:
        csv_bytes = st.session_state.pred_log.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="üì• Descargar CSV de predicciones",
            data=csv_bytes,
            file_name=f"predicciones_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True,
        )
        
        # Mostrar estad√≠sticas
        st.write("**Resumen del registro:**")
        st.write(f"- Total de registros: {len(st.session_state.pred_log)}")
        if not st.session_state.pred_log.empty:
            avg_confidence = st.session_state.pred_log['confidence'].mean() * 100
            st.write(f"- Confianza promedio: {avg_confidence:.1f}%")
            
            # Clase m√°s frecuente
            most_common = st.session_state.pred_log['label'].mode()
            if not most_common.empty:
                st.write(f"- Clase m√°s detectada: {most_common.iloc[0]}")

# =============================================================================
# 8. BUCLE PRINCIPAL DE ACTUALIZACI√ìN
# =============================================================================

if webrtc_ctx and webrtc_ctx.state.playing:
    # Inicializar transformer si es necesario
    if webrtc_ctx.video_transformer is None:
        webrtc_ctx.video_transformer = VideoTransformer()
    
    # Bucle de actualizaci√≥n
    max_iterations = 1000  # L√≠mite por seguridad
    for iteration in range(max_iterations):
        if not webrtc_ctx.state.playing:
            break
            
        vt = webrtc_ctx.video_transformer
        if vt is not None and vt.latest["class"] is not None:
            cls = vt.latest["class"]
            conf = vt.latest["confidence"]
            
            # Actualizar interfaz
            result_placeholder.markdown(
                f"**üéØ Clase detectada:** `{cls}`\n\n"
                f"**üìà Confianza:** `{conf*100:.2f}%`\n\n"
                f"**üî¢ Predicciones:** `{vt.prediction_count}`"
            )
            progress_placeholder.progress(min(max(conf, 0.0), 1.0))
            
            # Registrar predicci√≥n si est√° habilitado
            if enable_log:
                now = time.time()
                if now - st.session_state.last_log_ts >= log_every_n_seconds:
                    timestamp = datetime.utcnow().isoformat()
                    
                    # Agregar al DataFrame de sesi√≥n
                    new_row = pd.DataFrame([{
                        "timestamp": timestamp,
                        "label": cls,
                        "confidence": round(conf, 6)
                    }])
                    st.session_state.pred_log = pd.concat(
                        [st.session_state.pred_log, new_row], 
                        ignore_index=True
                    )
                    
                    # Guardar en base de datos
                    save_prediction_to_db(timestamp, cls, round(conf, 6))
                    st.session_state.last_log_ts = now
        
        time.sleep(0.1)  # Controlar frecuencia de actualizaci√≥n
        
    if iteration >= max_iterations - 1:
        st.sidebar.warning("‚ö†Ô∏è Bucle de actualizaci√≥n alcanz√≥ l√≠mite m√°ximo")

# =============================================================================
# 9. MODO ALTERNATIVO (SIN WEBRTC)
# =============================================================================

st.markdown("---")
with st.expander("üîÑ Modo alternativo: Clasificaci√≥n por imagen"):
    st.write("""
    **Usa este modo si:**
    - Tu navegador no soporta WebRTC
    - Tu red bloquea la transmisi√≥n de video
    - Prefieres clasificar im√°genes individuales
    """)
    
    uploaded_file = st.file_uploader(
        "Sube una imagen para clasificar",
        type=['jpg', 'jpeg', 'png'],
        help="Formatos soportados: JPG, JPEG, PNG"
    )
    
    if uploaded_file is not None:
        # Procesar imagen
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        
        if img is not None:
            # Mostrar imagen original
            st.image(img, channels="BGR", caption="üì∑ Imagen original", use_column_width=True)
            
            # Realizar predicci√≥n
            with st.spinner("üîç Analizando imagen..."):
                try:
                    resized = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)
                    x = resized.astype(np.float32).reshape(1, 224, 224, 3)
                    x = (x / 127.5) - 1.0
                    
                    pred = model.predict(x, verbose=0)
                    idx = int(np.argmax(pred))
                    label = labels[idx] if idx < len(labels) else f"Clase {idx}"
                    conf = float(pred[0][idx])
                
                    # Mostrar resultados
                    st.success(f"**üéØ Resultado:** {label}")
                    st.metric("üìä Confianza", f"{conf*100:.2f}%")
                    
                    # Mostrar todas las probabilidades
                    with st.expander("üìã Ver todas las probabilidades"):
                        for i, prob in enumerate(pred[0]):
                            class_name = labels[i] if i < len(labels) else f"Clase {i}"
                            st.write(f"{class_name}: {prob*100:.2f}%")
                    
                    # Registrar si est√° habilitado
                    if enable_log:
                        timestamp = datetime.utcnow().isoformat()
                        new_row = pd.DataFrame([{
                            "timestamp": timestamp,
                            "label": label,
                            "confidence": round(conf, 6)
                        }])
                        st.session_state.pred_log = pd.concat(
                            [st.session_state.pred_log, new_row], 
                            ignore_index=True
                        )
                        save_prediction_to_db(timestamp, label, round(conf, 6))
                        st.success("‚úÖ Predicci√≥n guardada en el registro")
                        
                except Exception as e:
                    st.error(f"Error durante la predicci√≥n: {e}")
        else:
            st.error("‚ùå No se pudo decodificar la imagen")

# =============================================================================
# 10. INFORMACI√ìN DEL SISTEMA
# =============================================================================

st.markdown("---")
with st.expander("üîß Informaci√≥n del sistema"):
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Archivos cargados:**")
        st.write(f"- Modelo: {MODEL_PATH} ({'‚úÖ' if os.path.exists(MODEL_PATH) else '‚ùå'})")
        st.write(f"- Etiquetas: {LABELS_PATH} ({'‚úÖ' if os.path.exists(LABELS_PATH) else '‚ùå'})")
        st.write(f"- N√∫mero de clases: {len(labels)}")
        
    with col2:
        st.write("**Estad√≠sticas de sesi√≥n:**")
        st.write(f"- Predicciones totales: {st.session_state.total_predictions}")
        st.write(f"- Registros guardados: {len(st.session_state.pred_log)}")
        if not st.session_state.pred_log.empty:
            st.write(f"- Primera predicci√≥n: {st.session_state.pred_log['timestamp'].iloc[0]}")
            st.write(f"- √öltima predicci√≥n: {st.session_state.pred_log['timestamp'].iloc[-1]}")

st.caption(f"√öltima actualizaci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Streamlit + TensorFlow + OpenCV")